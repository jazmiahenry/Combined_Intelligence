{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w_bDnwRG2LfZ",
    "outputId": "b9b48774-42b9-492a-818f-16377a2afc62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "tbmRVsYN2_8U",
    "outputId": "172d41f4-5b31-4ad7-fb9c-3a066b819b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JalYkHx3NWs"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwbgvG5D3Pfp"
   },
   "outputs": [],
   "source": [
    "path = glob.glob('/content/drive/My Drive/CombinedIntelligence/*.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxIDdVcu3hAa"
   },
   "outputs": [],
   "source": [
    "ls = []\n",
    "\n",
    "for file in path:\n",
    "  df = pd.read_csv(file, index_col=None, header=0)\n",
    "  ls.append(df)\n",
    "df1 = pd.concat(ls, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "fzhY6_qW39ms",
    "outputId": "fe279d6d-9be0-4160-c2a5-a1a89d0cdab2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country_code</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244051646071611394</td>\n",
       "      <td>860252856829587457</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>IMSS_SanLuis</td>\n",
       "      <td>Ante cualquier enfermedad respiratoria, no te ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-04T22:00:38Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244051645039706112</td>\n",
       "      <td>1125933654943895553</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>intrac_ccs</td>\n",
       "      <td>#ATENCIÓN En el Terminal Nuevo Circo se implem...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1030</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-08T01:21:16Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244051645975191557</td>\n",
       "      <td>80943559</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>rlieving</td>\n",
       "      <td>“People are just storing up. They are staying ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>604</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-10-08T21:06:08Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244051646750928897</td>\n",
       "      <td>817072420947247104</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>Tu_IMSS_Coah</td>\n",
       "      <td>Si empezaste a trabajar, necesitas dar de alta...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1827</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1549</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-05T18:17:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244051647032102914</td>\n",
       "      <td>788863557349670913</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>Tabasco_IMSS</td>\n",
       "      <td>Una sociedad informada está mejor preparada an...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-19T22:05:03Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607008</th>\n",
       "      <td>1256010435641462784</td>\n",
       "      <td>7117302</td>\n",
       "      <td>2020-04-30T23:59:58Z</td>\n",
       "      <td>ozsultan</td>\n",
       "      <td>Dear @NYCMayor,\\n\\nThe city has Millions to sp...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18897</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8723</td>\n",
       "      <td>7747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-27T20:09:29Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607009</th>\n",
       "      <td>1256010442876608512</td>\n",
       "      <td>912319950559354880</td>\n",
       "      <td>2020-04-30T23:59:59Z</td>\n",
       "      <td>DriveLockGlobal</td>\n",
       "      <td>In the middle of the #COVID19 sales surge in M...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365</td>\n",
       "      <td>1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-25T14:16:41Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607010</th>\n",
       "      <td>1256010442696245253</td>\n",
       "      <td>18198832</td>\n",
       "      <td>2020-04-30T23:59:59Z</td>\n",
       "      <td>TheScientistLLC</td>\n",
       "      <td>While the lockdown for #COVID19 continues on, ...</td>\n",
       "      <td>HubSpot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>978</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66844</td>\n",
       "      <td>383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-12-17T20:32:46Z</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607011</th>\n",
       "      <td>1256010440154513408</td>\n",
       "      <td>937899468585828352</td>\n",
       "      <td>2020-04-30T23:59:59Z</td>\n",
       "      <td>portarican_RT</td>\n",
       "      <td>Best answer. #COVID19 #WeMournThemAll https://...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>44903</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5503</td>\n",
       "      <td>5909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-05T04:20:33Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607012</th>\n",
       "      <td>1256010440007716867</td>\n",
       "      <td>1043656483</td>\n",
       "      <td>2020-04-30T23:59:59Z</td>\n",
       "      <td>Drz123Z</td>\n",
       "      <td>@WFXTMalini @CMichaelGibson @boston25 I had th...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.255987e+18</td>\n",
       "      <td>62144220.0</td>\n",
       "      <td>WFXTMalini</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5906</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Weymouth, MA</td>\n",
       "      <td>city</td>\n",
       "      <td>85</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-12-29T02:35:23Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14607013 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    status_id              user_id  ... verified lang\n",
       "0         1244051646071611394   860252856829587457  ...    False   es\n",
       "1         1244051645039706112  1125933654943895553  ...    False   es\n",
       "2         1244051645975191557             80943559  ...    False   en\n",
       "3         1244051646750928897   817072420947247104  ...    False   es\n",
       "4         1244051647032102914   788863557349670913  ...    False   es\n",
       "...                       ...                  ...  ...      ...  ...\n",
       "14607008  1256010435641462784              7117302  ...    False   en\n",
       "14607009  1256010442876608512   912319950559354880  ...    False   en\n",
       "14607010  1256010442696245253             18198832  ...     True   en\n",
       "14607011  1256010440154513408   937899468585828352  ...    False   en\n",
       "14607012  1256010440007716867           1043656483  ...    False   en\n",
       "\n",
       "[14607013 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivlpQRaKCqm8"
   },
   "outputs": [],
   "source": [
    "df2 = df1['text']\n",
    "y = df1['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiAibW0xDaRN"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "no_space = re.compile(\"[.;:!\\\"()\\[\\]]\")\n",
    "add_space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_text(df2):\n",
    "  text = [no_space.sub(\"\", line.lower()) for line in df2]\n",
    "  text = [add_space.sub(\" \", line) for line in df2]\n",
    "  return text \n",
    "\n",
    "clean_text = preprocess_text(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YO9S6K_NNjj6"
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elwdFyCyOOQK"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wskG993OdAF"
   },
   "outputs": [],
   "source": [
    "data = word_tokenize(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbpVTkpnPWDF"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkOw4U8fPl7M"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEOuhEUfPtSh"
   },
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXLkDl0eJPjn"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bK2R8wbxIqIc"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsnpFN3m50Hg"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30nNucPQ-GKV"
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCL2EacX-ac8"
   },
   "outputs": [],
   "source": [
    "regressor = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here is the LSTM model we will be using, I left the original as backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from textgenrnn import textgenrnn\n",
    "model_cfg = {\n",
    "    'word_level': True,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
    "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
    "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
    "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
    "    'max_length': 10,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
    "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
    "}\n",
    "\n",
    "train_cfg = {\n",
    "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
    "    'num_epochs': 2,   # set higher to train the model for longer\n",
    "    'gen_epochs': 2,   # generates sample text from model after given number of epochs\n",
    "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
    "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
    "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
    "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
    "}\n",
    "\n",
    "textgen=textgenrnn(name=\"CovidSentiment\")\n",
    "#I'm unsure where the actual text data is saved, but if you put a list of strings into x_train, it'll train on those with \n",
    "#Paramaters above, for as many expocs as you tell it to.\n",
    "textgenrnn.train_on_texts(x_train , num_epocs=2 , gen_epochs=2)\n",
    "#Saves a copy of the model we just built, which can be loaded later if needed\n",
    "textgen.save('covid.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 5 new tweets, that will match closely with the original, you can change temperature to chagne\n",
    "#Level of variance, 1 is most variant, 0 is least, .2, .5, and 1 are common temperatures\n",
    "textgen.generate(5, temperature=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pF8TI__z-ftZ"
   },
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "regressor.add(Dropout(.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(.2))\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eh9Uadob_rNZ"
   },
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')\n",
    "regressor.fit(x_train, y_train, epochs = 150, batch_size = 32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
